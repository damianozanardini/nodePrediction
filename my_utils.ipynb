{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some utilities\n",
    "\n",
    "These functions are here because they are supposed to be used in the main code and/or several graph-specific modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ogbl_citation2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damiano/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from my_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph\n",
    "import torch_geometric.utils as utils\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.generators import random_graphs\n",
    "\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import sys\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "import ogbl_citation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_of_reduced_graph(dir,module_name,n_nodes):\n",
    "    #return os.path.join(dir,f\"{sys.modules[module_name].get_graph_name()}_reduced_{n_nodes}\")\n",
    "    return os.path.join(dir,f\"{sys.modules[module_name].get_graph_name()}_reduced_{n_nodes}\")\n",
    "\n",
    "# Returns the n_max most frequent items from a tensor\n",
    "def get_most_frequent(my_tensor,n_max):\n",
    "    bincount = torch.bincount(my_tensor)\n",
    "    bincount_s,indices = torch.sort(bincount,descending=True)\n",
    "    return indices[:n_max]\n",
    "\n",
    "# Returns a reduced version of the graph with only n_nodes nodes\n",
    "# - if dense: nodes with highest degree are taken (otherwise, randomly chosen)\n",
    "# - if reverse: edges are reversed\n",
    "# - if clip: the rest of the nodes are NOT kept in the reduced graph\n",
    "# - if relabel_nodes: node ids are relabeled (from 0 to n_nodes-1)\n",
    "def reduce_graph(graph,n_nodes,dense=True,reverse=False,clip=False,relabel_nodes=False):\n",
    "    if dense:\n",
    "        # selects the nodes with a higher in-degree\n",
    "        nodes = get_most_frequent(graph.edge_index[1],n_nodes)\n",
    "    else:\n",
    "        # selects nodes randomly\n",
    "        nodes = random.sample(range(graph.num_nodes), n_nodes)\n",
    "\n",
    "    edges = subgraph(subset=nodes,edge_index=graph.edge_index,relabel_nodes=relabel_nodes)\n",
    "    if reverse:\n",
    "        r_edge_index = torch.stack([edges[0][1],edges[0][0]])\n",
    "    else:\n",
    "        r_edge_index = edges[0]\n",
    "\n",
    "    mask_n = torch.zeros(graph.num_nodes).byte()\n",
    "    for n in nodes:\n",
    "        mask_n[n] = True\n",
    "    if clip:\n",
    "        x = graph.x[mask_n]\n",
    "    else:\n",
    "        x = graph.x\n",
    "\n",
    "    return mask_n, Data(x=x,edge_index=r_edge_index) #,y=graph.y[mask_n])\n",
    "\n",
    "# For each experiment, a line is written to a local Excel file that contains the main figures:\n",
    "# Type of architecture, number of nodes, hyper-parameters, training time, accuracy, hits@k, MRR...\n",
    "def write_line_to_xlsx(dir,output):\n",
    "    current_GMT = time.gmtime()\n",
    "    time_stamp = calendar.timegm(current_GMT)\n",
    "    time_stamp = datetime.utcfromtimestamp(time_stamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    records = [tuple([time_stamp] + list(output.values()))]\n",
    "\n",
    "    wb = load_workbook(dir + \"tmp_results.xlsx\")\n",
    "    # Select First Worksheet\n",
    "    ws = wb.worksheets[0]\n",
    "\n",
    "    for record in records:\n",
    "        # Append Row Values\n",
    "        ws.append(record)\n",
    "\n",
    "    wb.save(dir + \"tmp_results.xlsx\")\n",
    "\n",
    "def print_time(topic,get_times,start_time):\n",
    "    if get_times:\n",
    "        print(f\"    *** {topic} time: {time.time()-start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of graphs\n",
    "\n",
    "Instead of the graph loaded from data, we can also load\n",
    "- A Barabási-Albert graph\n",
    "- An Erdös-Renyi random-generated graph\n",
    "- An egocentric network (based on the loaded data)\n",
    "- etc.\n",
    "\n",
    "The idea is that these graphs have (if possible) the same number of nodes, and a similar number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: this is repeated in the ogbl-citation2 module, since it is also needed there.\n",
    "# We should move it to a utils module if possible\n",
    "def get_random_features(n_nodes,num_node_features):\n",
    "    # random values in [0,1]\n",
    "    x = torch.rand(n_nodes,num_node_features).to(device)\n",
    "    # map values to [-1,1]\n",
    "    x = (x-0.5)*2\n",
    "    return x\n",
    "\n",
    "def get_dummy_features(n_nodes,num_node_features=3):\n",
    "    x = torch.ones(n_nodes,num_node_features).to(device)\n",
    "    return x\n",
    "\n",
    "# We could use directly the PyG function instead of NetworkX\n",
    "def get_barabasi_albert_graph(n_nodes,n_edges,num_node_features):\n",
    "    x = get_random_features(n_nodes,num_node_features)\n",
    "\n",
    "    G = random_graphs.barabasi_albert_graph(n_nodes, round(n_edges/n_nodes/2))\n",
    "    graph = utils.convert.from_networkx(G).to(device)\n",
    "    graph.x = x\n",
    "    return graph\n",
    "\n",
    "def get_erdos_renyi_graph(n_nodes,n_edges,num_node_features):\n",
    "    x = get_random_features(n_nodes,num_node_features)\n",
    "\n",
    "    p = n_edges/(n_nodes*n_nodes)\n",
    "    # According to the documentation, this implementation is faster for sparse graphs\n",
    "    G = random_graphs.fast_gnp_random_graph(n_nodes,p)\n",
    "    #G = random_graphs.erdos_renyi_graph(n_nodes,p)\n",
    "    graph = utils.convert.from_networkx(G).to(device)\n",
    "    graph.x = x\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building data for training / test\n",
    "\n",
    "We are splitting nodes into **training** and **test**.\n",
    "\n",
    "Due to the nature of the problem, the training graph has a subset of nodes and the corresponding edges. Moreover, edges are **reversed** in order to be able to build proper **computations graphs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_graph(graph,train_ratio,device):\n",
    "    # Computes the graph with only a percentage of nodes for training\n",
    "    train_mask, train_graph = reduce_graph(graph=graph,\n",
    "                                           n_nodes=round(graph.num_nodes*train_ratio),\n",
    "                                           dense=False,\n",
    "                                           reverse=True,\n",
    "                                           clip=False,\n",
    "                                           relabel_nodes=False)\n",
    "\n",
    "    nodes = torch.tensor(range(0,graph.num_nodes)).to(device)\n",
    "\n",
    "    train_nodes = nodes[train_mask]\n",
    "    test_mask = torch.logical_not(train_mask)\n",
    "    test_nodes = nodes[test_mask]\n",
    "\n",
    "    return train_graph, train_nodes, test_nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
