{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damianozanardini/nodePrediction/blob/main/NodePrediction_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOnGH8jsl5NL"
      },
      "source": [
        "# New node prediction\n",
        "\n",
        "## Damiano Zanardini and Emilio Serrano\n",
        "\n",
        "This work has been published as [New node prediction: a novel learning task for Graph Neural Networks](https://www.sciencedirect.com/science/article/pii/S0925231224012451?dgcid=coauthor).\n",
        "\n",
        "This notebook wants to be an implementation of the framework that is flexible in terms of the graph it works on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W57vvc3jEscl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzB9tYiDGcts"
      },
      "source": [
        "### Installs and imports\n",
        "\n",
        "We first will install [PyG](https://pyg.org/) (PyTorch Geometric), together with [ogb](https://github.com/snap-stanford/ogb) (Open Graph Benchmark) and the usual packages.\n",
        "\n",
        "Due to unknown reasons, to install PyG and related packages on Colab may lead to some unexpected behavior (namely, it may take nearly one hour instead of the usual 30/40 seconds). Because of this, we include a couple of code cells with code for installing PyG that worked properly at times in the past."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoEmIi1CJQX6",
        "outputId": "6a5eae31-4ecb-4462-a326-95a03259af68"
      },
      "outputs": [],
      "source": [
        "# This is the better-working approach so far\n",
        "\n",
        "drive = False # Should consider executing on Google Drive but also on our cluster, not only local\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['TORCH_DOWNPATH'] = \"https://pytorch-geometric.com/whl/\" # \"https://data.pyg.org/whl/\"\n",
        "\n",
        "if drive:\n",
        "    !pip uninstall torch-scatter torch-geometric --y\n",
        "\n",
        "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "    !pip install torch-scatter -f ${TORCH_DOWNPATH}torch-${TORCH}.html\n",
        "    !pip install torch-sparse -f ${TORCH_DOWNPATH}torch-${TORCH}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL3GZ4cyZ8eP"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "################################################################################\n",
        "# [NOT TO BE RUN NORMALLY] Alternatives for installing PyG (1) #################\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "!pip install torch_geometric\n",
        "\n",
        "# Optional dependencies:\n",
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9Tgj6bFGf5E"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "################################################################################\n",
        "# [NOT TO BE RUN NORMALLY] Alternatives for installing PyG (2) #################\n",
        "\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "\n",
        "#down_url = \"https://data.pyg.org/whl/\"\n",
        "down_url = \"https://pytorch-geometric.com/whl/\"\n",
        "\n",
        "# Installing torch-scatter, torch-sparse and torch-geometric is somehow painful\n",
        "# Sometimes it is necessary to change the download urls\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric --y\n",
        "\n",
        "!pip install torch-scatter -f {down_url}torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f {down_url}torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "#!pip install torch-geometric \\\n",
        "#  torch-sparse \\\n",
        "#  torch-scatter \\\n",
        "#  -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "\n",
        "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "#!pip install torch-geometric\n",
        "\n",
        "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a0avqbBNfui",
        "outputId": "8d27acf1-2373-406b-c06c-8022bde58878"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damiano/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "if drive:\n",
        "    !pip install ogb\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from networkx.generators import random_graphs\n",
        "\n",
        "import random\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch_geometric.utils as utils\n",
        "from torch_geometric.nn import GCNConv, ClusterGCNConv, GATConv, SAGEConv\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import subgraph\n",
        "\n",
        "import math\n",
        "from statistics import mean\n",
        "import calendar\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "if drive:\n",
        "    !pip install torchmetrics\n",
        "from torchmetrics import PearsonCorrCoef\n",
        "\n",
        "import sys\n",
        "\n",
        "import import_ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from ogbl_citation2.ipynb\n",
            "importing Jupyter notebook from my_utils.ipynb\n",
            "Initializing stored_graph to None\n",
            "Damiano\n"
          ]
        }
      ],
      "source": [
        "import ogbl_citation2\n",
        "import my_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Qb6WL87gMC"
      },
      "source": [
        "### Global vars/options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFejKNq57glO",
        "outputId": "464a89e1-6ea3-4053-eb7f-29275f781da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device is mps\n"
          ]
        }
      ],
      "source": [
        "# GPU is selected whenever available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    # This is for M-series-based Macs\n",
        "    if torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "print(f'Device is {device}')\n",
        "\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/NodePrediction/' if drive else os.getcwd()\n",
        "\n",
        "# The original graph\n",
        "graph_name = 'ogbl-citation2'\n",
        "\n",
        "# Given a graph, the proportion of train nodes vs. test nodes\n",
        "# (80%/20% is the split that is used in the paper)\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Whether computing times for the main training steps are shown\n",
        "get_times = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMbIRgz-SlRo"
      },
      "source": [
        "### Loading the selected type of graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LzygFaLu1SxI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_graph(graph_name,graph_type,n_nodes,node_features_type):\n",
        "    graph0 = sys.modules[graph_name].get_graph(n_nodes,node_features_type)\n",
        "\n",
        "    if graph_type == 'sample':\n",
        "        graph = graph0\n",
        "        g_type = \"Sampled\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "    elif graph_type == 'sample_undir':\n",
        "        graph = Data(x=graph0.x,edge_index=utils.to_undirected(graph0.edge_index))\n",
        "        g_type = \"Sampled (unidirected)\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "    elif graph_type == 'ego': # Requires big graph to be loaded\n",
        "        graph = my_utils.get_ego_network_un(n_nodes)\n",
        "        g_type = \"EGO\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "    elif graph_type == 'ba':\n",
        "        graph = my_utils.get_barabasi_albert_graph(n_nodes=n_nodes,n_edges=n_edges,num_node_features=num_features)\n",
        "        g_type = \"Barabási-Albert\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "    elif graph_type == 'er':\n",
        "        graph = my_utils.get_barabasi_albert_graph(n_nodes=n_nodes,n_edges=n_edges,num_node_features=num_features)\n",
        "        g_type = \"Erdös-Renyi\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "    elif graph_type == 'sample+ba':\n",
        "        graph = my_utils.get_sampled_plus_barabasi_albert_graph(n_nodes,num_features)\n",
        "        g_type = \"Sampled (+Barabási-Albert for test nodes)\"\n",
        "        n_train_nodes = round(n_nodes*train_ratio)\n",
        "        edges = subgraph(subset=list(range(n_train_nodes)),edge_index=graph.edge_index,relabel_nodes=False)\n",
        "        print(edges[0].shape)\n",
        "        train_graph = Data(x=graph.x,edge_index=edges[0])\n",
        "        nodes = torch.tensor(list(range(n_nodes)))\n",
        "        train_mask = torch.cat([torch.tensor([True]*n_train_nodes),torch.tensor([False]*(n_nodes-n_train_nodes))])\n",
        "        train_nodes = nodes[train_mask]\n",
        "        test_mask = torch.logical_not(train_mask)\n",
        "        test_nodes = nodes[test_mask]\n",
        "    else: # The \"else\" case is like sampled, but a warning message is output\n",
        "        graph = graph0\n",
        "        g_type = \"NOT SPECIFIED\"\n",
        "        train_graph, train_nodes, test_nodes = my_utils.get_training_graph(graph)\n",
        "\n",
        "    print(f\"{g_type} graph with {graph.num_nodes} nodes and {graph.num_edges} edges loaded\")\n",
        "\n",
        "    print(f'The train graph has {len(train_nodes)} (actual) nodes and {train_graph.num_edges} edges')\n",
        "    print(f'Number of test nodes: {len(test_nodes)}')\n",
        "\n",
        "    return graph.to(device), train_graph.to(device), train_nodes.to(device), test_nodes.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICPj_-EI-xKu"
      },
      "source": [
        "## Neural Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhHuhYs1Yw0n"
      },
      "source": [
        "### GNN architectures\n",
        "\n",
        "We have GCN, GAT, ClusterGCN and SAGE available.\n",
        "All architectures are a sequence of GNN layers of a given class, with ReLU between layers, and a configurable dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NuC4hpOQTphW"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "    self.convs.append(GCNConv(hidden_channels, out_channels))\n",
        "\n",
        "    self.norm = torch.nn.ModuleList()\n",
        "    for _ in range(num_layers-1):\n",
        "      self.norm.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv,norm in zip(self.convs[:-1],self.norm):\n",
        "      x = conv(x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      x = norm(x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "    return x\n",
        "\n",
        "class ClusterGCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(ClusterGCNConv(in_channels, hidden_channels))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(ClusterGCNConv(hidden_channels, hidden_channels))\n",
        "    self.convs.append(ClusterGCNConv(hidden_channels, out_channels))\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv in self.convs[:-1]:\n",
        "      x = conv(x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "    return x\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(GATConv(in_channels, hidden_channels))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
        "    self.convs.append(GATConv(hidden_channels, out_channels))\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv in self.convs[:-1]:\n",
        "      x = conv(x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "    return x\n",
        "\n",
        "class SAGE(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, aggr=\"add\"):\n",
        "    super(SAGE, self).__init__()\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(SAGEConv(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(SAGEConv(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
        "    self.convs.append(SAGEConv(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
        "\n",
        "    self.norm = torch.nn.ModuleList()\n",
        "    for _ in range(num_layers-1):\n",
        "      self.norm.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv,norm in zip(self.convs[:-1],self.norm):\n",
        "      x = conv(x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      x = norm(x)\n",
        "      running_mean = torch.mean(x, -1) # it can't go into the batch_norm function as a parameter\n",
        "      running_var = torch.var(x, -1) # it can't go into the batch_norm function as a parameter\n",
        "      # x = torch.nn.functional.batch_norm(x, running_mean, running_var)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0_drtM4NQf"
      },
      "source": [
        "### Architecture for **predictors**\n",
        "\n",
        "MLPNodePredictor\n",
        "  - takes an example (sources,target)\n",
        "  - computes an embedding **e_sources** that is the point-wise average of the embeddings corresponding to sources\n",
        "  - takes the embedding **e_target** corresponding to target\n",
        "  - concatenates **e_sources** with **e_target**\n",
        "  - applies a DL arquitecture to it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3W7dqw8RWKGH"
      },
      "outputs": [],
      "source": [
        "class NodePredictor(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NodePredictor, self).__init__()\n",
        "\n",
        "  def forward(self, examples, node_embs):\n",
        "    pass\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    pass\n",
        "\n",
        "class MLPNodePredictor(NodePredictor):\n",
        "  def __init__(self,embedding_size):\n",
        "    super(MLPNodePredictor, self).__init__()\n",
        "\n",
        "    # These numbers should better be powers of 2\n",
        "    hidden_dimension1 = round(embedding_size/2)\n",
        "    hidden_dimension2 = round(hidden_dimension1/4)\n",
        "\n",
        "    self.lin1 = torch.nn.Linear(2*embedding_size, hidden_dimension1)\n",
        "    self.lin2 = torch.nn.Linear(hidden_dimension1, hidden_dimension2)\n",
        "    self.lin3 = torch.nn.Linear(hidden_dimension2, 1)\n",
        "\n",
        "  def forward(self,examples,node_embs):\n",
        "    (sources,targets) = examples\n",
        "\n",
        "    # Computing embeddings for examples\n",
        "    # This has to be done each time because the last-generated node embeddings\n",
        "    # have to be used\n",
        "    sources_embs = torch.stack([node_embs[source.t()].mean(0) for source in sources])\n",
        "    sources_embs = torch.nan_to_num(sources_embs)\n",
        "    target_embs = torch.stack([node_embs[target] for target in targets])\n",
        "    x = torch.cat([sources_embs,target_embs], 1)\n",
        "\n",
        "    x = self.lin1(x)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.lin2(x)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.lin3(x)\n",
        "    out = torch.flatten(x)\n",
        "\n",
        "    return torch.sigmoid(out)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self.lin1.reset_parameters()\n",
        "    self.lin2.reset_parameters()\n",
        "    self.lin3.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esCgEqwcDpvr"
      },
      "source": [
        "## Example generation\n",
        "\n",
        "This code is in charge of generating **positive** and **negative** examples, for both **training** and **test**.\n",
        "\n",
        "What distinguishes a training example from a test one is the set of nodes the **target node** is taken from: either the train or the test portion of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z9nxwKtQPb3U"
      },
      "outputs": [],
      "source": [
        "# This function takes a set of nodes and returns a randomly generated subset of\n",
        "# it such that the ratio of selected nodes is between 'at_least' and 'at_most'\n",
        "# (both taking values between 0 and 1)\n",
        "def filter_nodes(nodes,at_least,at_most):\n",
        "    if at_least>at_most: # this should never happen\n",
        "        at_most = at_least\n",
        "\n",
        "    l = len(nodes)\n",
        "    # nodes are first shuffled\n",
        "    rand_indx = torch.randperm(l)\n",
        "    nodes = nodes[rand_indx]\n",
        "\n",
        "    mask = torch.rand(l)\n",
        "    mask = mask>0.5\n",
        "    for i in range(l):\n",
        "        if i<l*at_least: # nodes that DO have to be included\n",
        "            mask[i] = True\n",
        "        elif i>=l*at_most: # nodes that DO NOT have to be included\n",
        "            mask[i] = False\n",
        "\n",
        "    return nodes[mask]\n",
        "\n",
        "# This function generates a list of examples of type T with T in {pos,neg}.\n",
        "# This means that it comes up with randomly chosen pairs (S,t) such that\n",
        "# - S is a set of nodes\n",
        "# - t is a node\n",
        "# - if T is 'pos': a minimal proportion 'min_pure' of nodes s such that (s,t)\n",
        "#   is in the graph (a positive edge) is in S, and a maximal proportion\n",
        "#   'max_spurious' of nodes s such that (s,t) is not in the graph (a negative\n",
        "#   edge) is in S\n",
        "# - is T is 'neg': the other way around\n",
        "def generate_examples(type,total_nodes,target_nodes,train_sample_ratio,pos_edges,neg_edges,min_pure=1.0,max_spurious=0.0):\n",
        "    sources = torch.zeros(len(target_nodes),total_nodes).bool().to(device)\n",
        "    targets = torch.zeros(len(target_nodes)).int().to(device)\n",
        "\n",
        "    n = 0\n",
        "    rand_sample = torch.randperm(len(target_nodes))[:(round(train_sample_ratio*len(target_nodes)))]\n",
        "\n",
        "    for target in target_nodes[rand_sample]:\n",
        "        # pick randomly a node target with incoming edges\n",
        "        #target = target_nodes[random.randint(0,len(target_nodes)-1)]\n",
        "        # take nodes with POSITIVE outcoming edges pointing to target\n",
        "        pos_sources = pos_edges[0,pos_edges[1,:]==target]\n",
        "        # take nodes with NEGATIVE outcoming edges pointing to target\n",
        "        neg_sources = neg_edges[0,neg_edges[1,:]==target]\n",
        "\n",
        "        if type == 'pos':\n",
        "            # positive edges are considered as pure\n",
        "            filtered_pos_sources = filter_nodes(pos_sources,min_pure,1.00)\n",
        "            # negative edges are considered as spurious\n",
        "            filtered_neg_sources = filter_nodes(neg_sources,0.00,max_spurious)\n",
        "        else:\n",
        "            # positive edges are considered as spurious\n",
        "            filtered_pos_sources = filter_nodes(pos_sources,0.00,max_spurious)\n",
        "            # negative edges are considered as pure\n",
        "            filtered_neg_sources = filter_nodes(neg_sources,min_pure,1.00)\n",
        "\n",
        "        # this loop is for debug purposes only, when torch_scatter is nos imported\n",
        "        # for x in torch.cat([filtered_pos_sources,filtered_neg_sources]):\n",
        "        # sources[n][x] = True\n",
        "        sources[n].scatter_(dim=0, index=torch.cat([filtered_pos_sources,filtered_neg_sources]), value=True)\n",
        "        targets[n] = int(target)\n",
        "\n",
        "        n = n+1\n",
        "\n",
        "    return (sources,targets)\n",
        "\n",
        "# This function is supposed to generate labeled positive and negative examples\n",
        "# related to target nodes that are in a random set nodes of nodes.\n",
        "#\n",
        "# One positive and one negative example is generated for each target node\n",
        "def create_labeled_examples(total_nodes,target_nodes,edge_index,neg_edges,purity,train_sample_ratio=1.0):\n",
        "    n_pos_examples = n_neg_examples = round(train_sample_ratio*len(target_nodes))\n",
        "    # Positive examples are generated such as they have a node from 'nodes' as their target\n",
        "    (pos_sources,pos_targets) = generate_examples('pos',\n",
        "                                                total_nodes=total_nodes,\n",
        "                                                target_nodes=target_nodes,\n",
        "                                                train_sample_ratio=train_sample_ratio,\n",
        "                                                pos_edges=edge_index,\n",
        "                                                neg_edges=neg_edges,\n",
        "                                                min_pure = purity['min_pure'],\n",
        "                                                max_spurious = purity['max_spurious'])\n",
        "    pos_labels = torch.ones(n_pos_examples).to(device)\n",
        "    # Negative examples are generated such as they have a node from 'nodes' as their target\n",
        "    (neg_sources,neg_targets) = generate_examples('neg',\n",
        "                                                total_nodes=total_nodes,\n",
        "                                                target_nodes=target_nodes,\n",
        "                                                train_sample_ratio=train_sample_ratio,\n",
        "                                                pos_edges=edge_index,\n",
        "                                                neg_edges=neg_edges,\n",
        "                                                min_pure = purity['min_pure'],\n",
        "                                                max_spurious = purity['max_spurious'])\n",
        "    neg_labels = torch.zeros(n_neg_examples).to(device)\n",
        "\n",
        "    # Joining positive and negative examples and shuffling\n",
        "    train_sources = torch.cat([pos_sources,neg_sources]).to(device)\n",
        "    train_targets = torch.cat([pos_targets,neg_targets]).to(device)\n",
        "    train_labels = torch.cat([pos_labels,neg_labels]).to(device)\n",
        "    rp = torch.randperm(n_pos_examples+n_neg_examples)\n",
        "    return (train_sources[rp],train_targets[rp]), train_labels[rp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadkHHXYW-Pd"
      },
      "source": [
        "## Training driver\n",
        "\n",
        "The GNN runs on the train part of the graph (a complete subgraph with a portion of nodes, and the corresponding edges between them)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9zGQIV08W90k"
      },
      "outputs": [],
      "source": [
        "# Patience is the number of epochs after which we want to stop on no improvements\n",
        "def early_stopping(epoch,model,predictor,h,val_examples,val_labels,val_loss_history,best_val_loss,patience):\n",
        "    val_preds = predictor(val_examples,h)\n",
        "    val_correct_predictions = len([n for n in val_preds[val_labels==1.0] if n>=0.5]) + len([n for n in val_preds[val_labels==0.0] if n<0.5])\n",
        "    val_loss = loss_fn(val_preds, val_labels)\n",
        "    val_loss_history.append(val_loss.item())\n",
        "    print(f\"Computing validation loss: {val_loss.item():.4f}\")\n",
        "    if val_loss<best_val_loss:\n",
        "        print(f\"Saving best model (epoch {epoch})\")\n",
        "        torch.save(model.state_dict(),dir + \"best_model.pth\")\n",
        "        torch.save(predictor.state_dict(),dir+ \"best_predictor.pth\")\n",
        "        best_val_loss = val_loss\n",
        "    if len(val_loss_history)>patience:\n",
        "        x = val_loss_history[-(patience+1)]\n",
        "        es = True\n",
        "        for i in range(patience):\n",
        "            es = es & (x<=val_loss_history[-(patience-i)])\n",
        "        if es:\n",
        "            print(f\"Val loss {x:.4f} at epoch {len(val_loss_history)-patience} better than {val_loss_history[-patience:]}\")\n",
        "    else:\n",
        "        es = False\n",
        "    return (es,best_val_loss)\n",
        "\n",
        "def train(model,predictor,train_graph,train_nodes,train_sample_ratio,loss_fn,optimizer,batch_size,num_epochs,purity):\n",
        "    check_early_stopping = True\n",
        "\n",
        "    # Relative size of the validation set (only used with early stopping)\n",
        "    val_size = 0.1 if check_early_stopping else 0.0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    model.train()\n",
        "    predictor.train()\n",
        "\n",
        "    # Generating negative edges (once and for all)\n",
        "    neg_edges = utils.negative_sampling(train_graph.edge_index, num_nodes=len(train_graph.x),\n",
        "                                num_neg_samples=train_graph.edge_index.shape[1], method='dense').to(device)\n",
        "    # At training time, negative edges have to be restricted to the train graph\n",
        "    # Due to this, and to how negative edges are created, the number of negative\n",
        "    # edges comes to be a bit smaller than positive edges.\n",
        "    neg_edges = subgraph(subset=train_nodes,edge_index=neg_edges,relabel_nodes=False)[0]\n",
        "\n",
        "    # Keeping track of loss history, together with the best epoch for loss and accuracy\n",
        "    loss_history = []\n",
        "    val_loss_history = []\n",
        "    # To be returned later\n",
        "    # Minimum loss\n",
        "    min_loss = float('inf')\n",
        "    # Epoch at which the minimum loss is reached\n",
        "    min_loss_epoch = 0\n",
        "    # Maximum accuracy\n",
        "    max_acc = 0.0\n",
        "    # Epoch at which the maximum accuracy is reached\n",
        "    max_acc_epoch = 0\n",
        "\n",
        "    n_pos_examples = n_neg_examples = round(train_sample_ratio*len(train_nodes))\n",
        "\n",
        "    start_time = time.time() if get_times else 0\n",
        "    print(f\"Generating {n_pos_examples}+{n_neg_examples} total examples\")\n",
        "    (sources,targets), labels = create_labeled_examples(total_nodes=train_graph.num_nodes,\n",
        "                                                      target_nodes=train_nodes,\n",
        "                                                      train_sample_ratio=train_sample_ratio,\n",
        "                                                      edge_index=train_graph.edge_index,\n",
        "                                                      neg_edges=neg_edges,\n",
        "                                                      purity=purity)\n",
        "\n",
        "    # If needed, splitting into train and validation examples\n",
        "    limit = round(len(labels)*(1-val_size))\n",
        "    train_sources = sources[:limit]\n",
        "    train_targets = targets[:limit]\n",
        "    train_examples = (train_sources,train_targets)\n",
        "    train_labels = labels[:limit]\n",
        "    val_sources = sources[limit:]\n",
        "    val_targets = targets[limit:]\n",
        "    val_examples = (val_sources,val_targets)\n",
        "    val_labels = labels[limit:]\n",
        "    print(f\"{labels.shape[0]} examples generated: {train_labels.shape[0]} train examples + {val_labels.shape[0]} val examples\")\n",
        "    my_utils.print_time(\"Example-generation\",start_time)\n",
        "\n",
        "    print(f\"Positive labels: {train_labels.sum(-1)}\")\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        epoch_start_time = time.time() if get_times else 0\n",
        "        epoch_correct_predictions = 0\n",
        "        epoch_total_predictions = 0\n",
        "        epoch_total_loss = 0\n",
        "\n",
        "        for perm in DataLoader(range(train_examples[0].shape[0]), batch_size, shuffle=True):\n",
        "            batch_start_time = time.time() if get_times else 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            batch_examples = (train_sources[perm],train_targets[perm])\n",
        "            batch_labels = train_labels[perm]\n",
        "\n",
        "            # Using the GNN to generate node embeddings\n",
        "            # Embeddings are computed for ALL the training graph every time\n",
        "            start_time = time.time() if get_times else 0\n",
        "            h = model(train_graph.x, train_graph.edge_index)\n",
        "            my_utils.print_time(\"Node-embeddings\",start_time)\n",
        "\n",
        "            # Getting predictions for our batch, and computing the training loss\n",
        "            start_time = time.time() if get_times else 0\n",
        "            preds = predictor(batch_examples,h)\n",
        "            epoch_correct_predictions += len([n for n in preds[batch_labels==1.0] if n>=0.5]) + len([n for n in preds[batch_labels==0.0] if n<0.5])\n",
        "            epoch_total_predictions += preds.shape[0]\n",
        "            loss = loss_fn(preds, batch_labels)\n",
        "            epoch_total_loss += loss.item()\n",
        "            my_utils.print_time(\"Prediction\",start_time)\n",
        "\n",
        "            # Updating our parameters\n",
        "            start_time = time.time() if get_times else 0\n",
        "            loss.backward()\n",
        "            my_utils.print_time(\"Backpropagation\",start_time)\n",
        "            start_time = time.time() if get_times else 0\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            my_utils.print_time(\"Optimization\",start_time)\n",
        "            my_utils.print_time(\"Batch\",batch_start_time)\n",
        "\n",
        "        epoch_acc = 100*epoch_correct_predictions/epoch_total_predictions\n",
        "\n",
        "        # Updating loss and accuracy history\n",
        "        loss_history.append(epoch_total_loss)\n",
        "        if epoch_total_loss < min_loss:\n",
        "            min_loss = epoch_total_loss\n",
        "            min_loss_epoch = epoch\n",
        "        if epoch_acc > max_acc:\n",
        "            max_acc = epoch_acc\n",
        "            max_acc_epoch = epoch\n",
        "\n",
        "        if check_early_stopping:\n",
        "            patience = 8\n",
        "            es,bvs = early_stopping(epoch=epoch,\n",
        "                              model=model,\n",
        "                              predictor=predictor,\n",
        "                              h=h,\n",
        "                              val_examples=val_examples,\n",
        "                              val_labels=val_labels,\n",
        "                              val_loss_history=val_loss_history,\n",
        "                              best_val_loss=best_val_loss,\n",
        "                              patience=patience)\n",
        "            best_val_loss = bvs # updating best_val_loss\n",
        "            if es:\n",
        "                print(f'EARLY STOPPING AT EPOCH {epoch}; best model: epoch {epoch-patience}')\n",
        "                break\n",
        "\n",
        "        torch.save(model.state_dict(),dir + f\"model_{epoch}.pth\")\n",
        "        torch.save(predictor.state_dict(),dir+ f\"predictor_{epoch}.pth\")\n",
        "\n",
        "        print(f'Epoch {(epoch):4d} has loss {round(epoch_total_loss, 4):.4f}; ' +\n",
        "          f'correct predictions: {epoch_correct_predictions:6d} out of {epoch_total_predictions:6d} ' +\n",
        "          f'({epoch_acc:3.4f}%)')\n",
        "\n",
        "        my_utils.print_time(\"Epoch\",epoch_start_time)\n",
        "\n",
        "    return min_loss, min_loss_epoch, max_acc, max_acc_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyZ8qLMjoBiH"
      },
      "source": [
        "## Test driver\n",
        "\n",
        "This code\n",
        "- generates embeddings for previously unseen nodes (not belonging to the train graph)\n",
        "- generates positive and negative examples with those nodes as target\n",
        "- classifies the examples\n",
        "- returns several metrics: accuracy, Hits@K, MRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A2hb7pvZnztp"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(loss,test_correct_predictions,test_total_predictions):\n",
        "    acc = 100*test_correct_predictions/test_total_predictions\n",
        "    return acc\n",
        "\n",
        "def get_hits_at_k(k, test_examples, test_labels, preds):\n",
        "    pos_examples_preds = preds[test_labels==1.0]\n",
        "    n_pos = len(pos_examples_preds)\n",
        "    neg_examples_preds = preds[test_labels==0.0]\n",
        "    n_neg = len(neg_examples_preds)\n",
        "\n",
        "    hits = torch.tensor([len((neg_examples_preds>p).nonzero()) for p in pos_examples_preds])\n",
        "    h = len((hits<k).nonzero())/n_pos\n",
        "    return h\n",
        "\n",
        "def get_mrr(test_examples, test_labels, preds):\n",
        "    pos_examples_preds = preds[test_labels==1.0]\n",
        "    n_pos = len(pos_examples_preds)\n",
        "    neg_examples_preds = preds[test_labels==0.0]\n",
        "    n_neg = len(neg_examples_preds)\n",
        "\n",
        "    ranks = torch.tensor([len((neg_examples_preds>p).nonzero())+1 for p in pos_examples_preds])\n",
        "    ranks_reciprocal = torch.reciprocal(ranks)\n",
        "\n",
        "    mrr = (ranks_reciprocal.sum())/n_pos\n",
        "    return mrr.item()\n",
        "\n",
        "def test(model,predictor,test_graph,test_nodes,loss_fn,num_test_examples,purity):\n",
        "    num_nodes = len(test_graph.x)\n",
        "\n",
        "    # Generating negative edges (once and for all)\n",
        "    neg_edges = utils.negative_sampling(test_graph.edge_index, num_nodes=num_nodes,\n",
        "                                num_neg_samples=test_graph.edge_index.shape[1], method='dense').to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    test_examples, test_labels = create_labeled_examples(total_nodes=test_graph.num_nodes,\n",
        "                                                       target_nodes=test_nodes,\n",
        "                                                       edge_index=test_graph.edge_index,\n",
        "                                                       neg_edges=neg_edges,\n",
        "                                                       purity=purity)\n",
        "\n",
        "    # Use the GNN to generate node embeddings\n",
        "    h = model(test_graph.x, test_graph.edge_index)\n",
        "    # print(f'Model output: {h} (shape {h.shape})')\n",
        "\n",
        "    # Get predictions and compute the loss\n",
        "    preds = predictor(test_examples,h)\n",
        "    test_correct_predictions = len([n for n in preds[test_labels==1.0] if n>=0.5]) + len([n for n in preds[test_labels==0.0] if n<0.5])\n",
        "    test_total_predictions = preds.shape[0]\n",
        "\n",
        "    loss = loss_fn(preds, test_labels)\n",
        "\n",
        "    # Printing results\n",
        "    accuracy = get_accuracy(loss,test_correct_predictions,test_total_predictions)\n",
        "    print(f'Test loss: {round(loss.item(), 4)}; ' +\n",
        "          f'Accuracy (correct predictions): {test_correct_predictions} out of {test_total_predictions} ' +\n",
        "          f'({accuracy:.4f}%)')\n",
        "    hits = {}\n",
        "    num_neg_examples = len(preds[test_labels==0.0])\n",
        "    print(f\"Hits@k (wrt {num_neg_examples} negative examples): \", end=\"\")\n",
        "    for k in [1,2,3,5,10,20,30,50]:\n",
        "        hits[k] = get_hits_at_k(k, test_examples, test_labels, preds)\n",
        "        print(f\"k={k}: {hits[k]:.4f}; \", end=\"\")\n",
        "    print()\n",
        "    mrr = get_mrr(test_examples, test_labels, preds)\n",
        "    print(f\"MRR: {mrr:.4f}\")\n",
        "\n",
        "    return accuracy, hits, mrr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMoSu6pH-Lst"
      },
      "source": [
        "## Training and testing the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOR6fdQf-T3-"
      },
      "source": [
        "### Run configurations\n",
        "\n",
        "The **options** dictionary assigns values for different parameters.\n",
        "The following cell runs tests corresponding to such parameters.\n",
        "\n",
        "For each parameter, a list of values can be specified; if the list contains more than one value, then differnt test will be run.\n",
        "\n",
        "Ex. `options['sampled_nodes'] = [3000,10000]` runs experiments on the 3000-nodes and 10000-nodes of a graph.\n",
        "\n",
        "Moreover, it is possible to specify the value(s) of a parameter as dependent on some other parameter: for example, tha size of a batch may depend on the size of the graph. This can be done by assigning a dictionary, instead of a list, to a parameter.\n",
        "\n",
        "Ex. `options['batch_size'] = { 3000: [512], 10000: [2048], 20000: [4096], 50000: [8192] }` specifies a different value for the batch size depending on the size of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWPHV64p-kEU",
        "outputId": "1f39d18c-fcd3-41d9-c343-88ee635a6e1b"
      },
      "outputs": [],
      "source": [
        "graph_name = 'ogbl-citation2'\n",
        "\n",
        "options = {}\n",
        "\n",
        "# The type of graph\n",
        "options['graph_type'] = ['sample_undir'] #['sample','sample_undir','ego','ba','er','sample+ba']\n",
        "# The number of total nodes (in some graph types, like ego, the number of final node is normally bigger)\n",
        "# If the selected grph is smaller than this number, then it is taken as it is; otherwise, a sample is loaded or computed\n",
        "options['n_nodes'] = [3000]\n",
        "# Whether we use the original 128-dimensional vector of node features, or we compute stats-related ones, or we use dummy ones [1]\n",
        "options['node_features'] = ['original'] #['original','stats','dummy']\n",
        "# Type of GNN architecture\n",
        "options['GNN'] = [SAGE]\n",
        "# Number of layers (it should probably depend on 'sampled_nodes' and/or 'GNN')\n",
        "options['num_layers'] = { GCN: [5], ClusterGCN: [5], GAT: [5], SAGE: [5] }\n",
        "# Dropout coefficient (it should probably depend on 'GNN' and/or 'num_layers')\n",
        "options['dropout'] = { GCN: [0.2], ClusterGCN: [0.2], GAT: [0.2], SAGE: [0.2] }\n",
        "# Size of the embeddings vector computed by the GNN\n",
        "options['embedding_size'] = { GCN: [128], ClusterGCN: [128], GAT: [128], SAGE: [128] }\n",
        "# degree of purity (how many pure edges has to be included in an example, and how many spurious edges are allowed)\n",
        "# Let G be the graph under study, and G- be the negative graph (i.e., the graph\n",
        "# with the same nodes that is made of all the negative edges).\n",
        "\n",
        "# Given an example x=(S,t), that can be a positive or negative one, an edge e is\n",
        "# pure for x if both e and x have the same polarity (i.e., both positive or both\n",
        "# negative); otherwise, it is spurious\n",
        "\n",
        "# This parameter indicates how much \"impurity\" is allowed in an example:\n",
        "# Let t be the target node of the example; then, let S be the set of nodes in G\n",
        "# such that, for every s in S, the edge (s,t) is in G; let also S- be the set of\n",
        "# nodes in G- such that, for every s in S, the edge (s,t) is in G-. In other\n",
        "# words, given t, S (resp., S-) are the nodes connected to t by positive (resp.,\n",
        "# negative) edges.\n",
        "# The parameter min_pure indicates either\n",
        "# - the MINIMUM proportion of S that has to be included in a positive example on t; or\n",
        "# - the MINIMUM proportion of S- that has to be included in a negative example on t\n",
        "# The parameter max_spurious indicates either\n",
        "# - the MAXIMUM proportion of S that has to be included in a negative example on t; or\n",
        "# - the MAXIMUM proportion of S- that has to be included in a positive example on t\n",
        "#\n",
        "# For example, if we are considering a positive example, S contains 20 nodes, S-\n",
        "# contains 10 nodes, min_pure=0.8, max_spurious=0.2: the example will contain\n",
        "# AT LEAST 16=20*0.8 positive edges and AT MOST 2=10*0.2 negative edges\n",
        "#\n",
        "# Purity may be different at train and test time\n",
        "options['train_purity'] = [{'min_pure': 0.8,'max_spurious': 0.1}] # [{'min_pure': 1.0, 'max_spurious': 0.0},{'min_pure': 0.8,'max_spurious': 0.1},{'min_pure': 0.5,'max_spurious': 0.2}]\n",
        "# In general, one positive and one negative example is generated for every target node at training time; however, it is possible to specify a ratio of nodes for which examples are generated\n",
        "options['train_sample_ratio'] = [1.0]#,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
        "options['learning_rate'] = { GCN: [0.001,0.01,0.05], ClusterGCN: [0.001,0.01,0.05], GAT: [0.001,0.01,0.05], SAGE: [0.001] }\n",
        "options['test_purity'] = [{'min_pure': 0.8,'max_spurious': 0.1}] # [{'min_pure': 1.0, 'max_spurious': 0.0},{'min_pure': 0.8,'max_spurious': 0.1},{'min_pure': 0.5,'max_spurious': 0.2}]\n",
        "# the size of each training batch (it depends on 'sampled_nodes')\n",
        "options['batch_size'] = { 3000: [512], 10000: [2048], 20000: [4096], 50000: [8192] }\n",
        "# the number of training epochs\n",
        "options['num_epochs'] = [5]\n",
        "\n",
        "number_of_runs = 1 # This is used to run the same test several times\n",
        "\n",
        "n = 0\n",
        "for graph_type in options['graph_type']:\n",
        "  for n_nodes in options['n_nodes']:\n",
        "    for node_features in options['node_features']:\n",
        "      for gnn in options['GNN']:\n",
        "        for num_layers in options['num_layers'][gnn]:\n",
        "          for embedding_size in options['embedding_size'][gnn]:\n",
        "            for dropout in options['dropout'][gnn]:\n",
        "              for batch_size in options['batch_size'][sample_nodes]:\n",
        "                for num_epochs in options[\"num_epochs\"]:\n",
        "                  for train_purity in options['train_purity']:\n",
        "                    for train_sample_ratio in options['train_sample_ratio']:\n",
        "                      for learning_rate in options['learning_rate'][gnn]:\n",
        "                        for test_purity in options['test_purity']:\n",
        "                          n = n+1\n",
        "print(f'A total number of {n} learning tasks will be executed {number_of_runs} times')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLzfOv1X-Sj_"
      },
      "source": [
        "## Executing the battery of runs\n",
        "\n",
        "Experiments are run based on the values specified in the options dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkmAuLAFipX",
        "outputId": "d7345e56-4ac8-4038-8e90-64560cd84b25"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "this_run = 0\n",
        "while (this_run<number_of_runs):\n",
        "  for graph_type in options['graph_type']:\n",
        "    for n_nodes in options['n_nodes']:\n",
        "      for node_features in options['node_features']:\n",
        "        print(\"### DATA\")\n",
        "        graph, train_graph, train_nodes, test_nodes = get_graph(graph_name,graph_type,n_nodes,node_features)\n",
        "        num_features = len(graph.x[0])\n",
        "        for gnn in options['GNN']:\n",
        "          for num_layers in options['num_layers'][gnn]:\n",
        "            for embedding_size in options['embedding_size'][gnn]:\n",
        "              for dropout in options['dropout'][gnn]:\n",
        "                # Defining the neural architecture\n",
        "                hidden_dimension = embedding_size\n",
        "                print(f\"### MODEL: {gnn.__name__} with {num_layers} layers, {num_features} inputs, {hidden_dimension} hidden dimensions, and dropout {dropout}\")\n",
        "                # Doing the proper training\n",
        "                for batch_size in options['batch_size'][n_nodes]:\n",
        "                  for num_epochs in options[\"num_epochs\"]:\n",
        "                    for train_purity in options['train_purity']:\n",
        "                      for train_sample_ratio in options['train_sample_ratio']:\n",
        "                        for learning_rate in options['learning_rate'][gnn]:\n",
        "                          num_train_examples = round(train_sample_ratio*len(train_nodes))\n",
        "                          model = gnn(num_features,\n",
        "                                      hidden_dimension,\n",
        "                                      hidden_dimension,\n",
        "                                      num_layers=num_layers,\n",
        "                                      dropout=dropout).to(device)\n",
        "                          predictor = MLPNodePredictor(embedding_size=embedding_size).to(device)\n",
        "                          print(model)\n",
        "                          print(predictor)\n",
        "                          # Preparing training\n",
        "                          optimizer = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()), lr=learning_rate)\n",
        "                          print(f\"### TRAINING with {num_train_examples}+{num_train_examples} ({(100*train_sample_ratio):1f}% sample) train/val examples, purity ({train_purity['min_pure']}, {train_purity['max_spurious']}), batch_size = {batch_size}, num_epochs = {num_epochs}, learning rate = {learning_rate}\")\n",
        "                          start_time = time.time()\n",
        "                          min_loss, min_loss_epoch, max_acc, max_acc_epoch = train(model=model,\n",
        "                                                                                   predictor=predictor,\n",
        "                                                                                   train_graph=train_graph,\n",
        "                                                                                   train_nodes=train_nodes,\n",
        "                                                                                   train_sample_ratio=train_sample_ratio,\n",
        "                                                                                   loss_fn=loss_fn,\n",
        "                                                                                   optimizer=optimizer,\n",
        "                                                                                   batch_size=batch_size,\n",
        "                                                                                   num_epochs=num_epochs,\n",
        "                                                                                   purity=train_purity)\n",
        "                          end_time = time.time()\n",
        "                          train_time = end_time-start_time\n",
        "                          print(f\"Minimum loss:     {min_loss:.4f} reached at epoch {min_loss_epoch}\")\n",
        "                          print(f\"Maximum accuracy: {max_acc:.4f} reached at epoch {max_acc_epoch}\")\n",
        "                          print(f\"Training time: {train_time} s\")\n",
        "                          # Testing the results\n",
        "                          num_test_examples = len(test_nodes)\n",
        "                          for test_purity in options['test_purity']:\n",
        "                            n_tests = 5\n",
        "                            print(f\"\\n### TEST (x{n_tests}) with {num_test_examples}+{num_test_examples} examples and purity ({test_purity['min_pure']}, {test_purity['max_spurious']})\")\n",
        "                            accuracy = [0]*n_tests\n",
        "                            hits = [0]*n_tests\n",
        "                            mrr = [0]*n_tests\n",
        "                            # Loading best model and predictor\n",
        "                            model.load_state_dict(torch.load(dir + 'best_model.pth'))\n",
        "                            predictor.load_state_dict(torch.load(dir + 'best_predictor.pth'))\n",
        "                            for i in range(n_tests):\n",
        "                              accuracy[i], hits[i], mrr[i] = test(model=model,\n",
        "                                                                  predictor=predictor,\n",
        "                                                                  test_graph=graph,\n",
        "                                                                  test_nodes=test_nodes,\n",
        "                                                                  loss_fn=loss_fn,\n",
        "                                                                  num_test_examples=num_test_examples,\n",
        "                                                                  purity=test_purity)\n",
        "                            accuracy_mean = mean(accuracy)\n",
        "                            # neg_sources = neg_edges[0,neg_edges[1,:]==target]\n",
        "                            hits_mean = {}\n",
        "                            for k in hits[0].keys():\n",
        "                              hits_mean[k] = mean([hits[i][k] for i in range(n_tests)])\n",
        "                            mrr_mean = mean(mrr)\n",
        "\n",
        "                            print(f\"\\nAverage values (on {n_tests} test runs)\")\n",
        "                            print(f\"- Accuracy (correct predictions): {accuracy_mean:.4f}%\")\n",
        "                            print(f\"- Hits@k (wrt {num_test_examples} negative examples): \", end=\"\")\n",
        "                            for k in hits[0].keys():\n",
        "                              print(f\"k={k}: {hits_mean[k]:.4f}; \", end=\"\")\n",
        "                            print()\n",
        "                            print(f\"- MRR: {mrr_mean:.4f}\")\n",
        "\n",
        "                            output = {\n",
        "                              \"graph_type\": graph_type,\n",
        "                              \"graph_nodes\": graph.num_nodes,\n",
        "                              \"node_features\": node_features,\n",
        "                              \"gnn\": gnn.__name__,\n",
        "                              \"num_layers\": num_layers,\n",
        "                              \"embedding_size\": embedding_size,\n",
        "                              \"dropout\": dropout,\n",
        "                              \"num_train_examples\": num_train_examples,\n",
        "                              \"train_purity\": f\"({train_purity['min_pure']}, {train_purity['max_spurious']})\",\n",
        "                              \"batch_size\": batch_size,\n",
        "                              \"learning_rate\": learning_rate,\n",
        "                              \"num_epochs\": num_epochs,\n",
        "                              \"min_loss\": min_loss,\n",
        "                              \"min_loss_epoch\": min_loss_epoch,\n",
        "                              \"max_acc\": max_acc,\n",
        "                              \"max_acc_epoch\": max_acc_epoch,\n",
        "                              \"train_time\": train_time,\n",
        "                              \"num_test_examples\": num_test_examples,\n",
        "                              \"test_purity\": f\"({test_purity['min_pure']}, {test_purity['max_spurious']})\",\n",
        "                              \"accuracy_mean\": accuracy_mean,\n",
        "                              \"num_neg_examples\": num_test_examples,\n",
        "                              \"hits_mean1\": hits_mean[1],\n",
        "                              \"hits_mean2\": hits_mean[2],\n",
        "                              \"hits_mean3\": hits_mean[3],\n",
        "                              \"hits_mean5\": hits_mean[5],\n",
        "                              \"hits_mean10\": hits_mean[10],\n",
        "                              \"hits_mean20\": hits_mean[20],\n",
        "                              \"hits_mean30\": hits_mean[30],\n",
        "                              \"hits_mean50\": hits_mean[50],\n",
        "                              \"mrr_mean\": mrr_mean\n",
        "                            }\n",
        "\n",
        "                            write_line_to_xlsx(output)\n",
        "                            print(f\"### Learning task #{n+1} done\\n\\n\")\n",
        "                            n = n+1\n",
        "  this_run = this_run+1\n",
        "print(f'Executed {n} learning tasks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing stored_graph to None\n",
            "Damiano\n"
          ]
        }
      ],
      "source": [
        "%run \"./my_utils.ipynb\"\n",
        "%run \"./ogbl_citation2.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'stored_graph' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mogbl_citation2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<string>:11\u001b[0m, in \u001b[0;36mget_graph\u001b[0;34m(dir, n_nodes, node_features_type)\u001b[0m\n",
            "File \u001b[0;32m<string>:22\u001b[0m, in \u001b[0;36mcompute_reduced_graph\u001b[0;34m(num_nodes_to_sample)\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'stored_graph' referenced before assignment"
          ]
        }
      ],
      "source": [
        "g = ogbl_citation2.get_graph(dir,3000,'original')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNJgS4MTg3k8dXuOiEYwtNl",
      "include_colab_link": true,
      "mount_file_id": "148dWjcDDlhQKH9pOllbP2jJewUB9zAjK",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
